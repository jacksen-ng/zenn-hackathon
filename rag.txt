後半(様々な確率分布) 1
後半(様々な確率分布)
これからは前半で会得した確率論の考え⽅を利⽤して確率密度分布の具体的な形を⾒ていくよ．
第七回
これから物理的に起こるさまざまな具体的な分布を⾒ていく．
そしてモデル化していく．
これから勉強していく分布
⼆項分布
ポアソン分布
多項分布
超幾何分布
正規分布
⼆項分布
コインを投げるとする．
5回投げたとき表は何回出る？これはいきなり求められないから順番に考えていく．
コイン投げ
1. 1回の試⾏で表,裏が出る確率
2. 2回表が出る組み合わせ(場合の数)
3. 以上を合わせ
2回表が出る確率は
これを⼀般化していこう
⼀般化する
P表＝3
1
P裏＝3
2
P表＝3
1
P裏＝3
2
nCk = 5C2 = 10
5C2( )( ) =
3
1
2
3
2
(5−2)
f(2) =
243
80
P表＝p
P裏＝q = 1 − p後半(様々な確率分布) 2
回試⾏して， 回表が出る確率を考えよう．
すると，⼆項分布の式が出てくる．これが⼆項分布の確率質量関数．
⼆項分布の性質
⼆項分布の形は以下のパラメータで決まる．
パラメータは⽇本語で⺟数と⾔う．
⼆項分布の式
⼆項分布はnが⼤きくなると対称形に近づく．
の合計は1→規格化できている
普通に確率質量関数の⾯積は1って考えればいいだけ．
証明
は⼆項分布の式と⼀緒．これの和が1になればOK．
は1で，1の累乗は1なので証明完了．
実は⼆項分布の名前の由来は⼆項定理．⼆項定理を展開すると同じ形が出てくるから．
⼆項分布の平均
まず⼆項定理の式を考える．
ここに を作り出すことができれば期待値が出せる．
の を下ろしたい．てことで微分する．
が⼀個なくなったので両辺に をかける．
n x
f(x) = nCxp (1 −
x p)n−x
試⾏回数：n
確率：p
Bin(n, p)
f(x)
(p + q) =
n C p q
x=0
∑
n
n x
x n−x
nCxp q
x n−x
(p + q)
E[X] = xf(x)
x=0
∑
n
f(x) =
x=0
∑
n
C p q =
x=0
∑
n
n x
x n−x
(p + q)
n
x
p
x x
x C p q =
x=0
∑
n
n x
x−1 n−x n(p + q)n−1
p p後半(様々な確率分布) 3
これで⼆項分布の平均ができた．
⼆項分布の分散
分散は⼀次のモーメントと⼆次のモーメントがあれば出せるので⼆次のモーメントだけ出せばOK
んでどうするかというと，
をもう⼀回微分する．
⼆次のモーメントが求められた．早速分散にしてみよう．
できた．実は なので とも表すことができる．
第⼋回
⼤数の法則
⼆項分布の確率変数を から に変換したときに出てくる．これは何を意味するのか？
確率変数 は(例えばコインを投げて表がでた)回数に注⽬．
x C p q =
x=0
∑
n
n x
x n−x n(p + q) pn−1
xf(x) =
x=0
∑
n
np ≡ μ
∑ x C p q x=0
n
n x
x−1 n−x
x C p q
x=0
∑
n
n x
x−1 n−x
(x − x) C p q
x=0
∑
n
2 n xx−2 n−x
x C p q − x C p q
x=0
∑
n
2
n x
x−2 n−x
x=0
∑
n
n x
x−2 n−x
x C p q − x C p q
x=0
∑
n
2
n x
x n−x
x=0
∑
n
n x
x n−x
x C p q − np
x=0
∑
n
2
n x
x n−x
x C p q
x=0
∑
n
2
n x
x n−x
E[X ] = x C p q
2
x=0
∑
n
2
n x
x n−x
= n(p + q)
n−1
= n(n − 1)(p + q)
n−2
= n(n − 1)(p + q)
n−2
= n(n − 1)(p + q) p
n−2 2
= n(n − 1)(p + q) p
n−2 2
= n(n − 1)(p + q) p + np
n−2 2
= n(n − 1)p + np
2
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
σ
2
σ
2
= E[X ] − (E[X])
2 2
= n(n − 1)p + np − (np)
2 2
= np(1 − p)
(9)
(10)
(11)
(12)
q = 1 − p σ
2 = npq
X n
X
X後半(様々な確率分布) 4
確率変数 は(コインを投げて表が出た)割合に注⽬したもの．
実際に変換すると以下のようになっている．
の確率密度関数を ， の確率密度関数を とする．
より， したがって
何を表すかというと が⼤きくなるとその分 にスカラー倍されて⼤きい値を取るということ．
は が⼤きくなると分布は右に⾏きつつ縦の値が低くなっていくけど，
は がおきくなるとその分，縦の値が⾼くなるということ．
では実際に変換後の分布を⾒てみよう．まず というのは割合である．
を⼤きくすると分布はだんだん左側に寄っていく．
分布の左裾は0にものすごく近いので
がかかることによりもっともっと⼩さくなっていく．
が⼤きくなると分布が細くなる(ばらつきが少なくなる．)
⼤数の法則
n
X
X → =
n
X
Y
Y = ⇔
n
X
X = nY
X f(x) Y g(y)
g(y) = f(x)
dy
dx
X = nY dy =
dx n
g(y) = nf(x)
n f(x)
f(x) n
g(y) n
Y
n
n
n
→後半(様々な確率分布) 5
では，平均と分散について⾒ていく．
平均
⾒ての通り，標準偏差の分⺟に があるので， がおおきくなるにつれて標準偏差⾃体は⼩さくなるこ
とがわかる．
ポアソン分布
⼆項分布の⼀種
ポアソン分布とは，⼆項分布を⼆つの条件で単純化する．
1. ⼆項分布である⼀⽅の⽣起確率がすごく低い(
2. 何度も試⾏を繰り返す(
ポアソン分布の特徴
コイン投げの例
確率,試⾏回数： のとき
平均：
確率質量関数：⼆項分布より，
適当に計算すると，以下のようになっていく．
…
グラフにすると以下．急に下がるのがポアソン分布の特徴．
んで，最初に⾔ったとおり，
1. ⼆項分布である⼀⽅の⽣起確率がすごく低い(
2. 何度も試⾏を繰り返す(
f(x)
平均＝μx = np
分散 = σx
2 = np(1 − p)
変数変換：X → Y =
n
X
μy = μ =
n
1
x np =
n
1
p
σy＝ =
2
n2
σx
2
σ =
n2
1
x
2
n
p(1 − p)
σy =
n
p(1 − p)
n n
p << 1
n → ∞
P表 = 5
1
0 = 0.02,n = 100
μ = np = 2
f(x) = nCxp
x
(1 − p)
n−x
f(0) = 0.133, f(1) = 0.271, f(2) = 0.273, f(3) = 0.152
p << 1
n → ∞後半(様々な確率分布) 6
を適⽤するとかなり単純になる．
ポアソン分布の確率密度関数
では，導出しよう．
スタートは⼆項分布( )である．ここで を考える．
これは⾔うまでもないね．⼆項分布からスタートするので を置き換えるために を作った．
そして に を適⽤する，
ここで， になる(証明はあとで)
また
は全て になる．( が無限⼤になるので)
は有限だから (あとで説明する．)
導出完了．
の証明
命題
ある公式を使う．ん，これって の定義そのものでは？
まあいいや，命題を変形していく．
f(x) = e
x!
μ
x −μ
f(x) = nCxp
x
(1 − p)
n−x n → ∞
μ = np ⇔ p =
n
μ
p p = n
μ
f(x) = nCxp
x
(1 − p)
n−x n → ∞，μ = np
f(x) = ( ) (1 − ) x!
n ⋅ (n − 1)⋯(n − (x − 1))
n
μ x
n
μ n−x
= ⋅ 1 ⋅ (1 − ) ⋅ ⋯⋅ (1 − )(1 − ) (1 − )
x!
μ
x
n
1
n
x − 1
n
μ n
n
μ −x
(13)
(14)
n → ∞のとき，(1 − ) ＝e
n
μ n −μ
1 ⋅ (1 − ) ⋅ n
1 ⋯⋅ (1 − ) nx−1 1 n
μ (1 − n) =
μ −x 1
f(x) = e
x!
μ
x −μ
(15)
n → ∞のとき，(1 − ) ＝e
n
μ n −μ
(1 − n→∞lim ) ＝e
n
μ n −μ
e
(1 ±
m→∞
lim ) ＝e
m
1 m ±1
n ≡
′ とする． μ
n
(1 −
n→∞
lim ) ＝[ (1 −
n
1
′
n μ
′
n→∞
lim ) ]
n
1
′
n
′ μ
eの公式より，
e =
−1μ e−μ後半(様々な確率分布) 7
証明完了．
ん？ 使ってなくない？
実は使ってる．そこが，
は有限だから ってとこ．
に⽴ち返ってみると， である．
は無限⼤なので，これが有限になるためには がめっちゃ⼩さくないといけない．
って理由でこっそり出てきてた．
もし， がなかったら， はなかなか にならない．それこそ がマジで⾺⿅でかいときじ
ゃないとだめ．
でも
とかでもポアソン分布が使えるのは， のおかげ．
ポアソン分布を⼀般的な数式
まず⼆項分布の場合．パラメータは
ポアソン分布の場合．パラメータは のみ．( という条件を⼊れることでこうなった)
パラメータ数が⼆項分布より⼀個減るので⾃由度は1
※wikiとかでは は で書かれてたりする．
ポアソン分布の平均
ポアソン分布は なので は使えない．
実はポアソン分布の平均は であり，パラメータそのもの．
ポアソン分では，平均
のポアソン分布として書く．
だから， は与えられている数値だよ．
ポアソン分布の分散
⼆項分布の分散は だよ．でもポアソン分布のパラメータは だけなので だけでかきた
い．スタートは⼆項分布なので⼆項分布の分散の式を持ってくる．
p << 1
μ (1 − n) =
μ −x 1
μ μ = np
n p
p << 1 (1 − ) n
μ n 1 n
n = 100 p << 1
n, p
Bin(n, p)
μ p << 1，n → ∞
P(μ)：f(x) = e
x!
μ
x −μ
μ λ
n → ∞ n
μ
μ
E[X] = μ
μ
σ
2 = np(1 − p) μ μ
σ =
2 np(1 − p) = μ(1 − ) n
μ
n → ∞なので， ≃
n
μ
0
したがって，
σ =
2 μ
σ = μ後半(様々な確率分布) 8
ポアソン分布は平均も分散も なんだね．
第九回
今回は⼆項分布の兄弟，親戚の分布を学んでいく．
多項分布
各試⾏で 回のパターンのどれかが⽣起する場合，このとき， 番⽬のパターン(
)が何回起こるのか．
確率質量関数は以下
ただし，
ちなみに，多項定理を調べるともっと解像度上がる．
多項分布の確率質量関数は全然難しいことなくて，ただの⼆項分布の拡張．
興味があるのはある確率変数が何回でたかであり，何番⽬に出たかではないので順番は関係ない．
だから確率
の事象が何回起きたかを掛け合わせ， で良い．
簡単簡単．
多項分布の平均と分散
※平均も分散も各パターンごと， ごとに定義される．
超幾何分布
⼆項分布の親戚．⼆項分布で取り出したものを戻さないときの確率分布．
確率質量関数は以下．
超幾何分布の平均と分散
らしい．
μ
n i i ∈ N, 1 ≤ i ≤ m, 2 ≤
m
f(x1, x2, ..., xm(回)) = p p ⋯p
x1!x2!⋯xm!
n!
1
x1
2
x2 m
xm
n = x1 + x2 + ... + xm
p1 + p2 + ⋯+ pm = 1
p ((各確率変数が出た回数)!)
(全ての並びの場合のかず)
平均：μi = npi
分散：σi =
2 npi(1 − pi)
i
f(x) =
N Cn
M Cx ⋅ N−M Cn−x
N：全部の「もの」の数，M：「ものA」の数，N − M：「ものB」の数
n：試⾏回数，x：「ものA」を取り出す数，n − x：「ものB」を取り出す数
平均：μ = n N
M
分散：σ =
2
N (N − 1)
2
nM(N − M)(N − n)後半(様々な確率分布) 9
正規分布
⼆項分布から正規分布へ
の分布は のまわりに集中していく．(⼤数の法則)
が⼩さければ， が⼀定なら→ポアソン分布になる．
では， が⼩さくないとき を⼤きくするとどうなるのか
確率変数
を変数変換して新たな確率変数 を作る．(次の板書でかく)
その
が従う分布が→正規分布
確率変数
そうすると，実は確率密度は連続になる．
変数全体が で規格化されている．試しに に1を⼊れてみると上の式になる．
正規分布の導出
まず，⼆項分布は離散分布だった．しかし正規分布は連続である．
離散→連続このカラクリって⼀体何？
結論：試⾏回数が
であること．これにより連続になっている．
正規分布の導出のpoint
1. 離散確率変数 から連続確率変数 を作り出
2. ⼆項分布から正規分布を導
point1：離散から連続へ
スタートは⼆項分布．
⼆項分布の性質を持ち込んで考える．
※ は離散( )
だから
の微少量 だよ．え？なんでって？ 限界まで⼩さくしたら じゃん．(負は取らない)
で，そしたら連続である条件 にならないとだめ．てことで考える．
n
X p
p μ = np
p n
X Z
Z
Z
Z =
σ
X − μ
(μz = 0, σz = 1と規格化する)
g(z) = e
2π
1 − 2z2
なお，規格化されていない場合．
h(y) = exp[− ( ) ]
2πσy
1
2
1
σy
y − μy 2
σy σy
n → ∞
X Z
μ = np, σ =
2 np(1 − p)より
Z = =
σ
x − μ
np(1 − p)
x − np
x x = 0, 1, 2, ...
x Δx = 1 x 1
limn→∞ ΔZ = 0後半(様々な確率分布) 10
書き⽅間違えてそうだけど考え⽅はこう．そして，
完成． の極限が ならば．確率変数 は連続だね．
point2：⼆項分布から正規分布へ
以下の⼿順で進んでいく．
1. と の
2. と の
3. を で表現( の微分⽅程式を⽴てる
⼿順1 と の関係
⼿順2 と の関係
まず，このような関係があります．なんで成り⽴つかは調べて．
上の関係を利⽤しつつ の具体的な形を求めるよ．
まず， と の確率質量関数を考える． に をぶち込むことでこの⼆つの関数の
関係がわかるからね．
と は⼆項分布だからそのまま展開することで具体的な形がわかる.
んで，そのまま変形すると
と の関係が明らかになる．
ΔZ = Z(x + 1) − Z(x)
ΔZ = −
np(1 − p)
(x + 1) − np =
np(1 − p)
x − np
np(1 − p)
1
ΔZ =
n→∞
lim =
n→∞
lim
np(1 − p)
1
0
ΔZ 0 Z
f(x) g(z)
f (x)
f (x+1)
g(z)
g(z+Δz)
dz
dg(z) g(z) g(z)
g(z)
f(x) g(z)
g(z)Δz = f(x)Δx
g(z) = f(x) Δz
1
同様にして
g(z + Δz) = f(x + Δz
1
1)
f (x)
f (x+1)
g(z)
g(z+Δz)
=
g(z)
g(z + Δz)
f(x)
f(x + 1)
g(z)
g(z+Δz)
f(x) f(x + 1) f(x + 1) f(x)
f(x) f(x + 1)
f(x + 1) f(x)後半(様々な確率分布) 11
よしよし．
を利⽤することで， をもっとバラして考えることができるよ．
の関係式を使って，
今問題なのは左辺が についての関数なのに右辺が についての関数であること．
ここで
point1で作った以下の⼆つの変数変換の式が効いてくる．
の式ができた．これで右辺の を に置き換えることができる．
そしたら
の式に代⼊していこう．
で，実はこの状態で が邪魔． を消すために を作る．(なんで作るかはすぐわかる．)
f(x)
f(x + 1)
f(x + 1)
= nCxp (1 − p)
x n−x
= p (1 − p) x!(n − x)!
n! x n−x
= p (1 − p)
(x + 1)!(n − (x + 1))!
n! x+1 n−(x+1)
= pp
(x + 1)x!(n − x)!
n!(n − x) x
1 − p
(1 − p)
n−x
= f(x)
x + 1
n − x
1 − p
p
(16)
(17)
(18)
(19)
(20)
(21)
f(x + 1)
g(z)
g(z+Δz)
g(z) =
g(z+Δz)
f (x)
f (x+1)
=
g(z)
g(z + Δz) =
f(x)
f(x + 1)
(x + 1)(1 − p)
(n − x)p
Z x
Z =
np(1 − p)
x − np
ΔZ =
np(1 − p)
1
= ΔZ
Z
x − np
x = np + ΔZ
Z
x = x z
g(z)
g(z+Δz)
=
g(z)
g(z + Δz)
(x + 1)(1 − p)
(n − x)p
代⼊する．
=
g(z)
g(z + Δz)
((np + ) + 1)(1 − p) ΔZ
Z
(n − (np + ))p ΔZ
Z
n n np(1 − p)
Z後半(様々な確率分布) 12
ここでpoint1の以下の を利⽤する．
に代⼊する．
を消すことができた．この最終的な式が欲しかったやつ．
⼿順3 を で表現( の微分⽅程式を⽴てる．)
を考えるうえで，スタートは微分の定義そのもの
この式の右辺は⼿順2で作ったやつが⼊ってる．てことで代⼊していこう.
そして，微分なので をどんどん⼩さくしていく( なので は に収束する．)
この式は がその微分で表現されている．もしくは の微分がその関数そのもので表現されてい
る．これは微分⽅程式である．
g(z)
g(z + Δz) =
((np + ) + 1)(1 − p) ΔZ
Z
(n − (np + ))p ΔZ
Z
=
np(1 − p) + ( + 1)(1 − p) ΔZ
Z
np(1 − p) − p ΔZ
Z
(22)
(23)
ΔZ
ΔZ =
np(1 − p)
1
np(1 − p) = ( ) ΔZ
1 2
g(z) =
g(z+Δz)
np(1−p)+( +1)(1−p) ΔZ
Z
np(1−p)− p ΔZ
Z
=
g(z)
g(z + Δz)
+ ( + 1)(1 − p) ΔZ2
1
ΔZ
Z
− p ΔZ2
1
ΔZ
Z
右辺にΔZ
2をかける
=
g(z)
g(z + Δz)
1 + (zΔz + Δz )(1 − p)
2
1 − pzΔz
n
dz
dg(z) g(z) g(z)
dz
dg(z)
〜 dz
dg(z)
Δz
g(z + Δz) − g(z)
= ( − Δz
g(z + Δz)
1) Δz
g(z)
⼿順2の を代⼊する． g(z)
g(z + Δz)
= ( −
1 + (zΔz + Δz )(1 − p)
2
1 − pzΔz
1) Δz
g(z)
= g(z)
1 + (zΔz + Δz )(1 − p)
2
−z − Δz (1 − p)
2
(※ = g(z)では？？？まあ最終的な結果は同じ)
1 + (zΔz + Δz )(1 − p)
2
−z − Δz(1 − p)
Δz n → ∞ Δz 0
=
dz
dg(z) −zg(z)
g(z) g(z)後半(様々な確率分布) 13
我々は微分⽅程式を得た．あとは解くだけ．
⼿順4 を解く．
実は微分⽅程式の中でも⼀番解きやすいやつ．変数分離型微分⽅程式と⾔う．
の微少量 と の微少量 を両辺に分ける．(これが変数分離)
微少量が両辺に分かれた．
次は両辺を積分してやればいい．
logがあるのが嫌なので，両辺をexpの肩に乗せる．
はいできた．最初に紹介した正規分布の確率密度関数と⾒⽐べよう．
は定数なので とおける．⼀緒だ．じゃあついでに積分定数も求めよう．
は確率の規格化定数．
規格化定数 を求める．
積分定数についても求めることができた．正規分布の導出完了！！！！！！
第⼗回
正規分布の平均
以下の正規分布の式は規格化されていると⾔ったが，
この確率密度関数を
で積分すると になる．という意味での規格化ではない．
dz =
dg(z) −zg(z)
g(z) dg(z) z dz
dg(z) =
g(z)
1 −zdz
log g(z) = − z +
2
1 2 C
′
g(z)
g(z)
= e e C
′ − z21 2
= Ce− 2
z2
(24)
(25)
g(z) = e
2π
1 − 2z2
2π
1 C
C
C
∫ g(z)dz =
−∞
∞
C ∫ e dz =
−∞
∞
− 2
z2
1
公式：∫ e dz =
−∞
∞
− 2
z2
2πを利⽤すると
C 2π = 1
C =
2π
1
−∞ → ∞ 1後半(様々な確率分布) 14
平均
，分散 にするという意味での規格化である．
本当にこの式の平均は0なのか？分散は1なのか？確かめてみよう．
平均は0であることを⽰せた．
正規分布の分散
天下り的だけどまあこうなるから受け⼊れて．
正規分布の⼀般形
⼀般形というのは規格化されていないということ．(平均0分散1とは限らない．)
まず，以下のようにする． が によって定義されている感じだが，本来私たちは を で定義したい．
は規格化されている正規分布に従う確率変数．これに をかけたり を⾜したりすることで分布を⾃由
に引き伸ばしたり移動したりできる．
そんな⾃由な正規分布に従うのが確率変数
だよ．めちゃ⼤事
が従う分布の形を知りたいんよね．⼀般的な正規分布に従うんだけども．
形を知るのに，平均と分散を知ることは⽋かせない．
正規分布(⼀般形)の平均と分散
平均
期待値の公式を使う．んで なので
= 0 = 1
g(z) = e
2π
1 − 2z2
μz0 = E[Z] = ∫ zg(z)dz
−∞
∞
= ∫ z e dz
−∞
∞
2π
1 − 2z2
(26)
(27)
e− 2 は偶関数なので左右対称である．
z2
そこにZという切⽚0の⼀次関数をかけるので，0を基準に左と右で⾯積を打ち消しあう．
したがって，
μz0 = E[Z] = ∫ z e dx =
−∞
∞
2π
1 − 2z2
0
σz =
2 E[(z − μz ) ] =2 ∫ (z −
−∞
∞
μz ) e dx
2
2π
1 − 2z2
= z e dx =
2π
1 ∫
−∞
∞
2 − 2
z2
1
Z Y Y Z
Z = ⇔
σ
Y − μ
Y = σZ + μ
Z σ μ
Y
Y
μz = 0後半(様々な確率分布) 15
分散
分散の公式を使う．んで なので
どういうことか，
変数変換をしたときに使⽤した
がそのまま⼀般形の正規分布の平均，分散になっているということ．
さて，ここまでやって平均と分散を確認したところで，いよいよ正規分布の式に変数変換した確率変数
を代⼊してみよう．
突然分⺟に が出てきた感じになってるけど， の⽅の正規分布は分散が1なので省略されてただけ．そこ
が今回の に置き換わった．
正規分布の⼀般形が導出できた．
中⼼極限定理
「ほとんどの分布(⼆項,ポアソン,超幾何…etc)は のとき正規分布になる．」
これが適⽤できる分布の条件→分散が有限な分布
んーこれはちょっと納得いかないね…標本平均の平均が従うのが正規分布って覚えてるから確率論と統計
学ではここでちょっとだけ違うんだろう…
μy = σμz + μ = μy
σu
2 = 1
σy =
2 σ σ =2
z
2 σ2
μ, σ
2
Y
g(z) = e
2π
1 − 2z2
に代⼊
h(y) = g(z = )
σ
y − μ
h(y) = exp[− ( ) ]
2πσ
1
2
1
σ
y − μ 2
N (μ, σ ) =
2 exp[− ( ) ]
2πσ
1
2
1
σ
y − μ 2
σ Z
σ
n → ∞前半(確率論の考え⽅の基礎) 1
前半(確率論の考え⽅の基礎)
第⼀回
⽤語の定義
確率
未来について考える．偶然が起こる可能性を数値化
統計
過去について考える．起こったことがどのような分布に基づくか数値化(統計量と⾔
う．)
検定
起こったことが統計量で表せているのかを調べる⼿法．
標本空間
事象の集まり
根元事象
それ以上分けられない事象
他の確率
数学的確率
場合の数 / 全パターン
経験的確率
経験的にそう思うからそう，っていう確率．サイコロはみんな1/6だって経験的
に知ってるね．
経験的確率→統計的確率
試⾏し，結果がEだった回数 / 標本空間の⼤きさ
統計的確率は事後的に定義される．(統計というのは過去について考えるから
ね．)
期待値の⼀般化←⼀般化？？？期待値⾃体⼀般じゃないの？
P(E) = p =
n→∞
lim
n
r前半(確率論の考え⽅の基礎) 2
なぜ必要なの…
モーメント
の時の期待値．
k次のモーメントということ．
の時：
平均とは⼀次のモーメントということ．おおーすごい．期待値，平均の概念が⼀気
に広がった気がするね．
連続確率変数の期待値をどう計算するかがポイントだねー
第ニ回
今の流れ
確率密度関数→分布関数(確率密度関数より本質的)→期待値→モーメント(期待値
の特殊化)，平均，分散
期待値
確率変数 を⽤意する．
確率変数は に従う．
⼊⼒が確率変数の何かしらの関数．代表的な値のこと．
はどのような値を取るのか，どのような値を取ると期待されるのかを知りた
い．
ちなみに の分布もわからないのでどのような値を取るかの情報は確率密度関数
しかない．
ネタバレすると，期待値は以下の式で算出する．
シンプルに確率密度関数で重み平均をとってると思えばOK．
この式が基本的な期待値の式，これを特殊化していくと確率密度の特徴を表す代表
的な値を計算できる．
Φ(X) = Xk
E[X ] =
k
(x ) f(x )
i=1
∑
n
i
k
i
k = 1 E[X] = ∑i=1 x f(x ) =
n
i i μ
x
xf(x)
Φ(x)
Φ(x)
Φ(x)
∫ Φ(x)f(x)dx
−∞
∞前半(確率論の考え⽅の基礎) 3
平均
= の期待値
この時の が であることに注意．
もう⼀度⾔う，これが の期待値
もう少し変わった形を⾒てみよう．
平均の例
今から考えるのは具体的な で⾒てみようって話．
これが平均の例．よく出てくるね．
標準偏差
=確率密度の広がりを表現するもの．
統計の標準偏差ではなく，確率密度で考える標準偏差を考える．
んで，数学的にちゃんと定義するために先に分散について考える．
分散:
ポイントなのは分散の⽅がプライマリーであること．なんでだろうね．
分散も，何かの期待値である．数式で⾒ていこう.
これは元々の分布を平均0に座標変換してる．
分散も確率密度の重み平均で算出される．まあ期待値ってそういうもんだからね．
ここからモーメントという期待値をもっと特殊にした形を考える．
x
x Φ(x)
μ = ∫ xf(x)dx
−∞
∞
x
f(x)
f(x) = {xe (x ≥ 0)，0 (x < 0)
−x }
μ = ∫ xf(x)dx =
−∞
∞
∫ x e dx =
0
∞
2 −x 2
σ
2
σ =
2 ∫ (x −
−∞
∞
μ) f(x)dx
2前半(確率論の考え⽅の基礎) 4
確率変数の 乗というのはよく出てくる．以下の式だって の期待値， の期待
値，確率密度の積分(規格化により1
うん，こいつらはよく出てくるのでまとめよう．それがモーメント.
モーメント
=確率変数の~乗の期待値．
確率変数の 乗のモーメントは特別 次のモーメントというよ．
ふむふむ，てことは平均は⼀次のモーメントってことだね．式でかくとこれ
んでさっき出てきたニ次のモーメントはこれ
おーなんかすごいすごい．上の黒板の式をモーメントで記述していくと最終的によ
くみるあいつが出てくる．
k x
2 x1
k k
E[x] = ∫ xf(x)dx
−∞
∞
E[x ] =
2 ∫ x f(x)dx
−∞
∞
2前半(確率論の考え⽅の基礎) 5
出てきた．モーメントを知っているとこれが導出できるんやね．
第三回
第三回ではもっとモーメントについて深めていく．
⾼次のモーメント
モーメント⺟関数，期待値の性質．
モーメント⺟関数：ある確率変数の関数．その関数の期待値を求めていくことで⾼
次のモーメントを求めていくことができる．らしい．
復習(低次のモーメント)
低次のモーメント
⼀次のモーメントはそのまま平均で，ニ次のモーメントがわかっていれば分散が出
せる．
平均周りのモーメント
平均 μ = E[X]
分散
σ
2 = E[(X − μ) ]2
= E[X ] − μ
2 2
= E[X ] − E[X]
2 2
(1)
(2)
(3)前半(確率論の考え⽅の基礎) 6
平均まわりのモーメントとは… がポイント，これは平均が0にくるように分
布をシフトしてる．これが平均まわりってこと．平均周りの平均は0．平均まわりの
ニ次のモーメントが分散って⾔い換えられる．
これはどういうこと？何を表しているの？
三次関数と確率密度の積を取ると，確率密度がどれくらい偏っているかがわかる．
分布の偏りがないときは対称になる．
正の⽅向に偏っている場合．以下の図のような状況が出てくる．⾯積の合計は正．
逆に⾯積の合計が負になるときは確率密度は以下の図のように偏っている．
(X − μ)
分散 r = E[(X − μ) ]
3
(4)前半(確率論の考え⽅の基礎) 7
お次のテーマいこー
期待値の分配法則
略
のマクローリン展開
俺はこれよくわからないけど⼀回受け⼊れよう．
モーメント⺟関数
モーメント⺟関数は以下のように定義される．
を の多項式で表現すると，
の項と 次のモーメントの間に の の項の係数という関係．
ええ，すごいな，なんでいきなりこんな関係が出てくるんだろう…
e
x
e =
x 1 + x + x +
2!
1 2 x +
3!
1 3 ⋯
モーメント⺟関数：E[e ]
tx
E[e ]
tx
t
t
k k E[Xk
] = k!(E[e ])
tk
t
k前半(確率論の考え⽅の基礎) 8
⼀旦整理すると， 次のモーメントは の各項の係数と関係があるって⾔ってるの
よ．
それを考えるためにはまず がどういうふうな性質を持っているのか， がどうい
うふうな各実数の項にばらけていくのかを考える必要がある．
のマクローリン展開
各項について考えるためにマクローリン展開を考える．
まあこうなる．らしいよ．で！！！俺らが知りたがってるモーメント⺟関数は
だよね！！！！だからそのまま流れに任せて
の期待値を考えていくよ．
各項に分かれているので，期待値の分配法則が使える．やっていくよ．
※先⽣が⼤⽂字に書き直したので修正した.
ほいこんな感じ．では でくくろう．
できた， 次の項の形に注⽬するとこういう形が出てくる．すごいのはここから．
とおく． の係数(Coeficent)って意味で
そうすると，以下のようになる．
k e
tx
e
tx etx
e
tx
e =
tx 1 + tx + (tx) +
2!
1 2
(tx) +
3!
1 3 ⋯
E[e ]
tx
e
tx = 1 + tx + 2!
(tx) +
1 2
3!
(tx) +
1 3
⋯
E[e ]
tX = E[1 + tX + (tX) + (tX) + ⋯]
2!
1 2
3!
1 3
= E[1] + tE[X] + t E[X ] + t E[X ] + ⋯ 2!
1 2 2
3!
1 3 3
(5)
(6)
∑
E[e
tX ] = E[X ]t
k=0
∑
∞
k!
1 k k
k
k!E[X ] ≡
1 k Ck t
k Ck
E[X ] =
k!
1 k Ck
E[X ] =
k k!Ck前半(確率論の考え⽅の基礎) 9
次のモーメントがこんなにもスッキリ表せた．
具体的な確率密度でモーメントを求めてみる！！！
板書そのまま
k前半(確率論の考え⽅の基礎) 10
最終的に がもとまるのがアツい． 次のモーメントが知りたかったら を⼊れてい
けば求められる．
実際に求める．
Ck k k前半(確率論の考え⽅の基礎) 11
気になれば好きなだけ⾼次のモーメントを調べてみてください！
だけは絶対覚える！！！！！！！！！！！
第四回
復習
⼤事なもの
第⼀回
確率変数
確率密度関数(確率密度，本質的な違いはない．)
分布関数
第⼆回
期待値，モーメント
確率密度の状態を表す量，代表値を導⼊．
第三回
モーメント⺟関数
次のモーメントを求める．
今回．
確率変数の変数変換．
変換をしたときに確率密度関数がどのように変化するのかを⾒てみる．
E[Xk] = k!Ck
k前半(確率論の考え⽅の基礎) 12
確率変数の変数変換
確率変数 → に変換する．変換するだけはシンプルだから何も問題ない．
確率密度関数 }確率密度関数．この⼆つの関数の間の関係を知りたい．
以下のような変数変換があったときに， では同じなのに， では幅(？)が ⼤きく
変わっている．
X Y
f(x) g(y)
x y前半(確率論の考え⽅の基礎) 13
これは絵の間違いではなくて実際にそういう変換をしている．引き伸ばされるよう
な変換ね．
このとき確率密度関数はどのように変わっているのだろうか？
実際には以下のようになっている．右側が引き伸ばされている．&密度が⼩さくなっ
ている．前半(確率論の考え⽅の基礎) 14
この微⼩なところを と とすると，これらは に依存する．
確率変数 が をとる確率を考えると，そこは塗りつぶした区間の⾯積に
なる．確率は⾯積だからね．んで，どちらも確率密度関数なので全部の⾯積は1.0．
でも でも対応する区間であれば，確率変数が をとる確率は変わらない！
Δx Δy XとY
X, Y Δx, Δy
X Y Δ前半(確率論の考え⽅の基礎) 15
え，まって は勝⼿に決めただけだからどう対応しているのかはわかってなく
ない？
→ の極限をとる．てことで を微分するよん． ができた．
ができた．いいねいいね．そして以下のように変形できる．
これは， を の関数として表したものを で微分したもの．これが今回の核⼼．
残りはこれを利⽤してこねくり回す．
以下で にしているのは，考えるべきものが で で微分したもののため．
Δx, Δy
Δx, Δy 0 Δx, Δy dx, dy
f(x)dx = g(y)dy
f(x)dx = g(y)dy
g(y) = f(x)∣ ∣
dy
dx
x y y
x＝ dy
dx xをy前半(確率論の考え⽅の基礎) 16
のままだと，左辺は の関数で右辺は の関数って現象が起きるので
を代⼊する．
できた．これで がわかっていれば も出せるようになった．
⼀次変換による確率変数変換の⼀般的性質
ここでは確率変数変換によって平均と分散がどのように変わっていくか⾒ていく．
f(x) y x x = ax +
b
f(x) g(x)前半(確率論の考え⽅の基礎) 17
変換前
変換後
もうちょいちゃんと⾔えば変換前のやつらで変換後のやつらがどうやって表せる
か．を考える．
ではまず について考えよう．
⼤前提
変換後の平均を変換前の確率変数(またそれらで得られるモーメン
ト)で表してみる．
おーーーー，統計でよく⾒る形が出てきた！！！！！
順番に変換していけばよく⾒るこの形が導出できるんだね．
次に について考えよう．
変換後の分散を変換前の確率変数(またそれらで得られるモーメン
ト)で表してみる．
f(x)
μx
σx
2
g(y)
μy
σy
2
μy
Y = aX + b
μy = E[y]
μy
= ∫ yg(y)dy
−∞
∞
= ∫ (ax + b)f(x)∣ ∣dy
−∞
∞
dy
dx
= ∫ (ax + b)f(x)dx
−∞
∞
= a ∫ xf(x)dx + b f(x)dx
−∞
∞
∫
−∞
∞
= a ∫ xf(x)dx + b
−∞
∞
= aμx + b
(7)
(8)
(9)
(10)
(11)
(12)
σy
2前半(確率論の考え⽅の基礎) 18
おーーーーこれもよく⾒たことあるやつだ．
こいつらはシンプルでよく使うやつ．もう⼀個考えよう．
1つの に2つの が対応する場合
これをどうやって数式で表せるの…？
⼆つの項を⾜し合わせて計算する．
σ = E[y] y
2
σy
2
= ∫ (y − μ ) g(y)dy
−∞
∞
y
2
= ∫ (ax + b − μ ) f(x)∣ ∣dy
−∞
∞
y
2
dy
dx
= ∫ (ax + b − (aμ + b)) f(x)∣ ∣dy
−∞
∞
x
2
dy
dx
= ∫ (ax + b − (aμ + b)) f(x)dx
−∞
∞
x
2
= ∫ a(x − μ ) f(x)dx
−∞
∞
x
2
= a (x − μ ) f(x)dx
2 ∫
−∞
∞
x
2
= a σ
2
x
2
(13)
(14)
(15)
(16)
(17)
(18)
(19)
y x前半(確率論の考え⽅の基礎) 19
ほんでいつものように計算する．
を求める．これは，ただ を で微分しただけだから何も問題ないね，
だよ
で， に代⼊する．で， の関数だから の変数を に変えて終了．
実は今⽇は確率変数の変換と⾔いながら確率密度関数の変換を⾒ていっていた．
確率は保存されるので変換前後の確率密度関数の
の積分を で結ぶことで式ができた．
その式をいじくり回すと⼀般適性質．(
なり なり)ができる．
んで，⼀つの確率変数 に⼆つの確率変数 が対応する場合は場合分けして，線型
結合してあげれば普通に計算できる．そんな難しことじゃない．
第五回
今回のテーマは同時確率分布
同時確率分布
そもそもが異なる⼆つの確率変数があるとする．(独⽴)
⭐️確率分布(分布関数，確率密度関数)が⼆次元関数になる．(これが最⼤の特
⼆次元の分布関数(離散)
板書そのまま，サイコロの例
g(y)Δy = f(x)Δx + f(−x)Δx
g(y)dy = f(x)dx + f(−x)dx
g(y) = f(x) + f(−x)
dy
dx
dy
dx x y X = ± y
=
dy
dx
(± ) =
dy
d
y
2
1
y
1
g(y) y x y
g(y) = (f(x) + f(−x))
2
1
y
1
g(y) = (f( ) +
2 y
1
y f(− y))
Δ =
μx = aμx + b σy
2 = a σ2
x
2
Y X前半(確率論の考え⽅の基礎) 20
⼆次元の確率密度関数 (連続)
確率密度関数と⾔いつつ，確率を出してみる．
確率変数 が微少量 に落ちる確率．確率密度関数を微⼩区間について積
分することで確率が得られる．
X, Y Δx, Δy前半(確率論の考え⽅の基礎) 21
⼆次元の分布関数(連続)
単純に確率密度関数を積分してるだけ
ただ忘れてはいけないことがあるよね，ニ変数でも規格化されていること．
以下がニ変数の確率密度関数，および分布関数の規格化条件
F(x, y) = ∫ f(x , y )dy dx
∞
x
∫
∞
y
′ ′ ′ ′前半(確率論の考え⽅の基礎) 22
周辺確率(離散)
ニ変数で登場する新しい概念．
ちょっとよくわからないので板書そのまま．( には特別な意味はない)
によらないというのは， 全てに対してということ．だから の取りうるものを全て
たす．
f1
y y y前半(確率論の考え⽅の基礎) 23
周辺確率(連続)，周辺分布関数(連続)
注⽬して欲しいのはインテグラルの中にそのまま確率密度関数が⼊っていること．
周辺分布関数は周辺確率をそのまま積分しただけ．前半(確率論の考え⽅の基礎) 24
ちょっとわかりづらいかもだけど，簡単に⾔えば によらないときの の確率密度関
数(それが周辺確率)だよ．あとはそれを積分したら周辺分布関数になった．それだ
け．
条件付き確率
条件付き確率はあくまで確率密度関数だよ．ここ忘れないでね．
さっきは によらない．だったけど
今度は
がある特定の値をとったときの の確率密度だよ．それだけの違い．
さあ説明するよ．
はただニ変数の確率密度関数 に を代⼊したもの．それだけ！
でも注意して欲しいのが，
も確率密度関数であるため，規格化されている必要がある．
そこで
に規格化定数をかけることで規格化するよ．
規格化定数
に対して規格化されていないといけない．だから規格化定数 をつけて調整する．
んで，すごいのはこれ．説明は後，まず⾒てみて．
以下は単純に に を代⼊したもの．
y x
y
y x
f(x∣y1) f(x, y) y = y1
f(x∣y1)
f(x, y)
x a
∫−∞f(x∣y )dx ≡
∞
1 1 f(x∣y1) = af(x, y)前半(確率論の考え⽅の基礎) 25
説明する．これは結合確率(ニ変数の確率密度関数，同時確率)を について積分した
もの．それが1になるのは説明済．すごいのは，これが の周辺確率になっているこ
と．
周辺確率では
によらない の確率密度関数を考えた．条件付き確率では による の確率密度関
数，を考えた．
による の確率密度関数を考えたら結果的に についての周辺確率が出た．⾔い換
えると によらない の確率密度関数が出てきたのよ〜
ベイズの定理
すると，条件付き確率,結合確率,周辺確率の関係がわかる．(説明は板書の後に)
x
y
y x y x
y x y
x y前半(確率論の考え⽅の基礎) 26
規格化定数 の形に変形して， に代⼊する．すると
が出てくる．これはベイズの定理そのもの．
の条件付き確率は結合確率(同時確率,ニ変数の確率密度関数)割る の周辺確率で出
せる．
⼆つが決まれば後⼀つは出るので⾃由度は2．すごい！！！！！！！！！！！！
結合確率(同時確率)と周辺確率の関係(まとめ)
2つの確率変数が独⽴している場合．(逆にこれが成り⽴つことが独⽴の条件)
同時確率は，それぞれの確率変数の周辺確率の積で表すことができる．
以上．
第六回
a = f(x∣y1) = af(x, y)
f(x∣y1) =
f2(y)
f(x, y)
y y
f(x, y) = f1(x)f2(y)前半(確率論の考え⽅の基礎) 27
今回も確率変数が⼆変数のとき，同時確率の続き
前回は結合確率密度関数を導⼊したね．
今回は同時確率の期待値を考えていく．そして共分散と相関係数について導⼊す
る．
期待値(同時確率)
確率密度関数 に対する の期待値．
は 両⽅について規格化されている．
連続
離散
もしくは
平均,分散(同時確率)
の の平均．
とする．
確率変数が⼆つあるので両⽅について積分する．
注意なのは，式を計算しても は出てこない．これは定義，そう決めた．
これは に無関係な の平均． がどのような値を取るかわからないが，その中で
はどういう値を取ると期待できるかがこの式．
平均
f(x, y) Φ(x, y)
f(x, y) x, y
E[Φ(x, y)] = ∫ Φ(x, y)f(x, y)dydx
−∞
∞
∫
−∞
∞
E[Φ(x, y)] = Φ(x , y )f(x , y )
i=1
∑
m
j=1
∑
n
i j i j
E[Φ(x, y)] = ∑∑Φ(xi, yj )pi,j
f(x, y) X
X = Φ(x, y)
E[X] = ∫ xf(x, y)dydx
−∞
∞
∫
−∞
∞
≡ μxと書く
μx
Y X Y
X前半(確率論の考え⽅の基礎) 28
分散
今まで出てきた平均，分散を拡張しただけ．⽚⽅について考えただけ．
だから両⽅の変数に関わる量を紹介する．
共分散
連続
この式は定義そのもの． が変わるだけ．
⼆乗はついてないけど次元は合ってる．確率変数の次元として捉えるんだね．
離散
相関係数
相関係数は共分散から計算することができる．
→ と の関係を知ることができる．
相関係数
共分散は確率変数の⼆乗の次元．
標準偏差は確率変数の⼀乗の次元．
てことは相関係数は⼆乗を⼆乗で割っていることになるので次元のない値になる．
(⽐の値になる)
μx = E[X]：Xの平均
μy = E[Y ]：Y の平均
σx =
2 E[(X − μx)2
]：Xの分散
σy =
2 E[(Y − μy )2
]：Y の分散
σxy = E[(X − μx)(Y − μy )]：共分散
= ∫ ∫ (x −
−∞
∞
μx)(y − μy )f(x, y)dydx
Φ
σxy = (x −
i=1
∑
m
j=1
∑
n
i μx)(yj − μy )f(xi, yj )
X Y
ρxy = ：相関係数
σxσy
σxy前半(確率論の考え⽅の基礎) 29
実は⾃動的に規格化もされている．(
)
と がどのような関係を持っているのか，確率密度を⾒ながら考えることにな
る．
相関係数が規格化されていることの証明( の証明)
まず以下を考える．
ここから何をやるのか． が正になると⾔って，不等式を
⽴てる．
そんで証明する．
以下の計算で，共分散，両変数の分散が出てくる．
→相関係数の登場⼈物が全員出てくるのが嬉しい．
0にしてやることで左辺の をとって の形に落とし込める．
で，突然だけど以下の式を考える．期待値と=ではないことに注意してね．
⼀部は⼀致してるね．これを使って期待値の式をいじってやる．
で，どんな でも って⾔いたいので
−1 ≤ ρxy ≤ 1
X Y
−1 ≤ ρxy ≤ 1
E[(λ(X − μx) + (Y − μy )) ]
2
(λ(X − μx) + (Y − μy ))
2
≥ −1 ≤ hoge ≤ 1
E[(λ(X − μx) + (Y − μy )) ]
2
= λ σ +
2
x
2 2λσxy + σy ≥2 0
σx(λ +
2 ) =
σx
2
σxy 2 λ σ +
2
x
2 2λσxy +
σx
2
σxy
2
λ σ +
2
x
2 2λσxy = σx
(λ +
2 ) −
σx
2
σxy 2
σx
2
σxy
2
E[(λ(X − μx) + (Y − μy )) ]
2
= λ σ +
2
x
2 2λσxy + σy ≥2 0
= σx(λ +
2
) +
σx
2
σxy 2 σy −
2
σx
2
σxy
2
= σx(λ +
2 ) +
σx
2
σxy 2 − (σ −
σx
2
1
xy
2 σxσ ) ≥2
y
2 0
λ ≥ 0
2 2 2前半(確率論の考え⽅の基礎) 30
でないといけない．この式の意味は
では式を操作していく．
証明完了．
相関係数の値とX,Yの確率密度関数
のとき，要は無関係．確率密度関数は円形に分布する．
のとき， が⼤きくな
ると jは⼩さくなる．要は負の相関
がある．
のとき， が⼤きくな
ると も⼤きくなる．要は正の相関
がある．
σxy −
2 σxσ ≤2
y
2 0
(共分散) −
2
(Xの分散) (Y の分散) ≤
2 2 0
σxy −
2 σxσ ≤2
y
2 0
σxy ≤
2 σxσ2
y
2
≤
σx
2σy2
σxy
2
1
(相関係数) ≤
2 1
ρxy ≤
2 1
∣ρxy ∣ ≤ 1
−1 ≤ ρxy ≤ 1
ρxy = 0
1 ≥ ρxy > 0 x
y
1 ≥ ρxy > 0 x
y前半(確率論の考え⽅の基礎) 31
これが今回のクライマックス
X,Yが独⽴のとき( )
独⽴のとき，同時確率は， の周辺確率と の周辺確率の積で表される．
の周辺確率というのは， によらない時の確率密度関数．
の周辺確率というのは， によらない時の確率密度関数．
直感的にはすぐわかる．独⽴しているときは以下のように同時確率が相関なしの等
⾼線みたいになるよね．
ρxy, σxy = 0
X Y
X Y
Y X
f(x, y) = f1(x)f2(y)前半(確率論の考え⽅の基礎) 32
数式で証明する．
共分散 を代⼊する．
と に分けられる．
と 形が同じなのでどっちかについて考えればOK
は1だよね． は
したがって
についても全く同じなので，
ついでに
注意！！！！！！！！
確率変数 が独⽴ならば，共分散,相関係数は0だけど，
共分散,相関係数が0だから確率変数
が独⽴だとは⾔えない！！！！！！
※補⾜
え，ちょっと待って！今回の授業では じゃないの！？
今回は確率変数が独⽴なので である．したがって．
σxy f(x, y) = f1(x)f2(y)
σxy = ∫ ∫ (x −
−∞
∞
μx)(y − μy )f(x, y)dydx
= ∫ ∫ (x −
−∞
∞
μx)(y − μy )f1(x)f2(y)dydx
X Y
= ∫ (x −
−∞
∞
μx)f1(x)dx ∫ (y −
−∞
∞
μy )f2(y)dy
X Y
= ∫ xf (x)dx −
−∞
∞
1 μx ∫ f (x)dx
−∞
∞
1
∫ f (x)dx −∞
∞
1 ∫ xf (x)dx −∞
∞
1 μx
= μx − μx
= 0
Y
σxy = 0
ρxy = σ σ = x y
σxy 0
X, Y
X, Y
μx = ∫ ∫ xf(x, y)dydx −∞
∞
f(x, y) = f1(x)f2(y)前半(確率論の考え⽅の基礎) 33
証明完了．
第七回
今回は，⼆つの確率変数の和の分布を考えていく．
まず，確率変数 を⽤意する．
そしてこの⼆つの確率変数の和を，確率変数
とする．
我々は，今 がどのような分布になるのか．( の分布と の分布の関係性)を知
りたい．
そこで確率密度関数を考える．
確率密度関数
で素直に
の確率密度関数も考えたいんだけど．⼆つの確率変数から⼆つの確率変数への変
換として捉えた⽅が，何かと便利．ということで．
確率変数
確率変数
を考える．今 は後で扱いやすいから置いただけだよ．
そして確率密度関数を考える．
確率密度関数
そしてポイント．周辺確率をとる．
周辺確率
周辺確率
μx = ∫ ∫ xf(x, y)dydx
−∞
∞
= ∫ ∫ xf (x)f (y)dydx
−∞
∞
1 2
= ∫ xf (x)dx f (y)dy
−∞
∞
1 ∫
−∞
∞
2
μx = ∫ xf (x)dx
−∞
∞
1
X, Y
Z = X + Y
Z Z X, Y
f(X, Y )
Z
Z = X + Y
W = Y
W
g(Z,W)
g1(Z)
g2(W)前半(確率論の考え⽅の基礎) 34
は によらない確率密度関数だから，これの分布を考えることが の分
布を考えることになるね．
ニつの確率変数の変換
以前⼀つの確率変数の変換を勉強したが，今回は⼆つの確率変数の変換と捉えるこ
とで簡単になる．
この式は3次元(確率変数⼆つ,密度)で考えたときに，体積が等しくなる．これは確
率．
ではでは， を⼩さくした極限を考える．
この関係はヤコビの⾏列式
dxdyがどのくらいスカラー倍されるかを表す．
g1(Z) W X＋Y
g(z, w)ΔzΔw = f(x, y)ΔxΔy
ΔxΔy
g(z, w)dzdw = f(x, y)dxdy前半(確率論の考え⽅の基礎) 35
結論， で同じってこと．ヤコビの⾏列式を使うとこれが⽰せた．
そしてこっから何するかというと， まで戻る．
もう察した？
ってこと，ただ，問題が… がクッソ邪魔なんだよなあ…
実は数式の字⾯上では，
の関数が の関数に等しいというのはおかしい．
だから
そのものを で変換しておく必要がある．
にする．
ここで
である．以下のように変形する．
したがって，
dzdw
dzdw
= dxdy
∂x
∂z
∂x
∂w
∂y
∂z
∂y
∂w
= dxdy
∂x
∂(x+y)
∂x
∂y
∂y
∂(x+y)
∂y
∂y
= dxdy
1
0
1
1
= 1dxdy = dxdy
(20)
(21)
(22)
(23)
(24)
dzdw = dxdy
g(z, w)dzdw = f(x, y)dxdy
g(z, w) = f(x, y)
w
z, w x, y
x, y z, w
＝zとwの関数
z = x + y
w = y
x = z − y
= z − w
g(z, w) = f(z − w, w)前半(確率論の考え⽅の基礎) 36
で，知りたいのは を知りたいので周辺化，周辺確率を求める．
これが2つの確率変数 の和( )の分布．⼀つ⽬の答え．
これが⼀般化された答え．超重要．
こっからは特殊な場合を考える．
確率変数 が独⽴しているとき( と の「畳み込み積分」)
が独⽴しているとき，
独⽴している時，同時確率はそれぞれの確率密度関数の積だよ．
これが⼆つ⽬の答え．これは以下のように⾔い換えることができる．
と の「畳み込み積分」
畳み込み積分(convolution)
確率論に限らない⼀般的な数学の概念．
が でぼかされた．と解釈できる．
g1(z)
g1(z) = ∫ g(z, w)dw
−∞
∞
= ∫ f(z − w, w)dw
−∞
∞
(25)
(26)
(27)
X, Y = Z
X, Y f1 f2
X, Y f(x, y) = f1(x)f2(y)
g1(z) = ∫ f(z −
−∞
∞
w)f2(w)dw
f1 f2
f1(x) ⊗ f2(y)
f1(x)(orf2(y)) f2(y)(orf1(x))前半(確率論の考え⽅の基礎) 37
だから，
g1(z)は畳み込みで表される．